{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sam3\n",
    "import torch\n",
    "\n",
    "sam3_root = os.path.join(os.path.dirname(sam3.__file__), \"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration flags for notebook demo\n",
    "save_frames = True  # set True to save per-frame overlays\n",
    "visualize_frames = False  # set False to disable cv2.imshow window\n",
    "output_dir = os.path.join(sam3_root, \"outputs\", \"real_time\",\"bedroom_stream\")\n",
    "output_video = os.path.join(output_dir, \"bedroom_stream.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-12-02 11:16:25,845 2232124 sam3_video_base.py: 124:\u001b[0m setting max_num_objects=10000 and num_obj_for_compile=16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'db75b180-4ff0-4cb5-963b-08561531a813'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sam3.model_builder import build_sam3_stream_predictor\n",
    "\n",
    "# Initialize predictor (single-GPU streaming)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "predictor = build_sam3_stream_predictor(device=device)\n",
    "\n",
    "resp = predictor.handle_request({\"type\": \"start_session\"})\n",
    "session_id = resp[\"session_id\"]\n",
    "session_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video properties: 960x540 at 30.0 FPS\n"
     ]
    }
   ],
   "source": [
    "# Open video and stream frames\n",
    "import os, cv2\n",
    "\n",
    "video_path = os.path.join(sam3_root, \"assets\", \"videos\", \"bedroom.mp4\")\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 0)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)\n",
    "\n",
    "print(f\"Video properties: {width}x{height} at {fps} FPS\")\n",
    "\n",
    "writer = None\n",
    "if output_video:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(output_video, cv2.CAP_FFMPEG, fourcc, fps, (width, height))\n",
    "if save_frames and not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "frame_idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frame 199. Current peak memory: 6.22 GB, Overall peak memory: 6.22 GB.\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-12-02 11:17:26,003 2232124 sam3_stream_predictor.py: 182:\u001b[0m removed session db75b180-4ff0-4cb5-963b-08561531a813; live sessions: [], GPU memory: 5120 MiB used and 6714 MiB reserved (max over time: 6375 MiB used and 6714 MiB reserved)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 frames in 56.26s => 3.55 FPS6.23 GB, Overall peak memory: 6.23 GB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Streaming loop\n",
    "from sam3.visualization_utils import render_masklet_frame\n",
    "import time\n",
    "processed = 0\n",
    "peak_memory = 0.0  # GB\n",
    "start_time = time.time()\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame_bgr = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "        # Push frame\n",
    "        predictor.handle_request({\"type\": \"add_frame\", \"session_id\": session_id, \"frame\": frame_rgb})\n",
    "        # Add text prompt only on first frame\n",
    "        if frame_idx == 0:\n",
    "            predictor.handle_request({\"type\": \"add_prompt\", \"session_id\": session_id, \"frame_index\": 0, \"text\": \"a kid\"})\n",
    "        # Run per-frame inference\n",
    "        resp = predictor.handle_request({\"type\": \"run_inference\", \"session_id\": session_id, \"frame_index\": frame_idx})\n",
    "        outputs = resp.get(\"outputs\")\n",
    "        if outputs is not None:\n",
    "            overlay = render_masklet_frame(frame_rgb, outputs, frame_idx=frame_idx, alpha=0.5)\n",
    "        else:\n",
    "            overlay = frame_rgb\n",
    "        # Save per-frame overlay\n",
    "        if save_frames:\n",
    "            out_path = os.path.join(output_dir, f\"frame_{frame_idx:05d}.png\")\n",
    "            cv2.imwrite(out_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "        # Append to output video\n",
    "        if writer is not None:\n",
    "            writer.write(cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "        # Visualize\n",
    "        if visualize_frames:\n",
    "            cv2.imshow(\"SAM3 Streaming\", cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "            # Press ESC to stop\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "        # Update running statistics\n",
    "        frame_idx += 1\n",
    "        processed += 1\n",
    "        current_peak_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB\n",
    "        peak_memory = max(peak_memory, current_peak_memory)\n",
    "        print(\n",
    "            f\"Processed frame {frame_idx}. \"\n",
    "            f\"Current peak memory: {current_peak_memory:.2f} GB, \"\n",
    "            f\"Overall peak memory: {peak_memory:.2f} GB.\"\n",
    "        , end=\"\\r\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "    if visualize_frames:\n",
    "        cv2.destroyAllWindows()\n",
    "    predictor.handle_request({\"type\": \"close_session\", \"session_id\": session_id})\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "fps_est = processed / elapsed if elapsed > 0 else 0.0\n",
    "print(f\"Processed {processed} frames in {elapsed:.2f}s => {fps_est:.2f} FPS\")\n",
    "processed\n"
   ]
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "captumWidgetMessage": [],
  "fileHeader": "",
  "fileUid": "8685c221-c143-4b84-98ec-b1f023cedd6c",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "last_base_url": "https://bento.edge.x2p.facebook.net/",
  "last_kernel_id": "b57809cb-57de-4b58-a47a-2cd14cd7dc51",
  "last_msg_id": "be2245fc-daa1cc5649ef79144c475c5d_1965",
  "last_server_session_id": "4fb65252-bdbd-4eea-b3c3-4a9f2995ad48",
  "notebookId": "825823386977069",
  "notebookNumber": "N8482762"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
